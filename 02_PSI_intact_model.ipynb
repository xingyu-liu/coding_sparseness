{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from dnnbrain.io.fileio import ActivationFile\n",
    "from activation_PSI import Dnn_act, sparseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify custom paremeters\n",
    "root = os.getcwd() # root directory of analysis\n",
    "net = 'alexnet' # ['alexnet', 'vgg11']\n",
    "dataset = 'imagenet'  # ['imagenet', 'caltech256', 'caltech143']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare parameters\n",
    "net_dir = os.path.join(root, net)\n",
    "caltech256_label = pd.read_csv(os.path.join(root, 'caltech256_label'), sep='\\t')\n",
    "if dataset == 'imagenet':\n",
    "    stim_per_cat = 50\n",
    "elif dataset in ['caltech256', 'caltech143']:\n",
    "    stim_per_cat = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dnn actiation\n",
    "if dataset == 'caltech143':\n",
    "    dnnact_path = os.path.join(\n",
    "            net_dir, 'dnn_activation', '{0}_{1}.act.h5'.format(net, 'caltech256'))\n",
    "else:\n",
    "    dnnact_path = os.path.join(\n",
    "            net_dir, 'dnn_activation', '{0}_{1}.act.h5'.format(net, dataset))\n",
    "    \n",
    "dnnact_alllayer = ActivationFile(dnnact_path).read()\n",
    "layer_name = list(dnnact_alllayer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PSI\n",
    "bins = 20 # bins for activation histogram\n",
    "sp = []\n",
    "sp_bincount = []\n",
    "pdf_bin = []\n",
    "\n",
    "for layer in layer_name:\n",
    "    dnnact = Dnn_act(dnnact_alllayer[layer], stim_per_cat=stim_per_cat)\n",
    "    dnnact_catmean = dnnact.cat_mean_act()[0][:, :, 0]\n",
    "    \n",
    "    if dataset == 'caltech143':\n",
    "        dnnact_catmean = dnnact_catmean[caltech256_label['imagenet1000'] == '0', :]\n",
    "\n",
    "    dnnact_catmean_z = np.nan_to_num(stats.zscore(dnnact_catmean, 0))\n",
    "\n",
    "    # PSI\n",
    "    sparse_p = sparseness(dnnact_catmean_z.T, type='s', norm=True)\n",
    "    sp_bincount.append(pd.cut(sparse_p, np.linspace(0, 1, bins+1)).value_counts().values\n",
    "                       /dnnact_catmean.shape[0] * 100)\n",
    "\n",
    "    sp.append(np.squeeze(sparse_p))    \n",
    "    print('{0} done'.format(layer))\n",
    "    \n",
    "    # pdf\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dnnact_catmean_z_norm = min_max_scaler.fit_transform(dnnact_catmean_z.T)\n",
    "    \n",
    "    dist_bin = [np.histogram(dnnact_catmean_z_norm[:,i], bins=np.arange(0,1,0.01),density=True)[0] for i \n",
    "                in range(dnnact_catmean_z_norm.shape[-1])]\n",
    "    pdf_bin.append(np.asarray(dist_bin).mean(0))\n",
    "\n",
    "sp_bincount = np.asarray(sp_bincount).T\n",
    "pdf_bin = np.asarray(pdf_bin).T\n",
    "sp_median = np.array([np.nanmedian(sp[i]) for i in range(len(sp))])\n",
    "np.save(os.path.join(net_dir, 'PSI_{0}.npy'.format(dataset)),sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Fig 1A or SS Fig 2A\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=[4,6])\n",
    "layer_legend = [layer.split('_')[0] for layer in layer_name]\n",
    "# Conv\n",
    "conv_colors = sns.color_palette('Blues', n_colors=len(layer_legend[:-2]))\n",
    "[axes[0].plot(np.linspace(0, 1, bins+1)[1:], sp_bincount[:,i], c=conv_colors[i]) for i in range(len(layer_legend[:-2]))]\n",
    "axes[0].set_xlim((0,0.6))\n",
    "axes[0].legend(layer_legend[:-2])\n",
    "# FC\n",
    "fc_colors = sns.color_palette('Oranges', n_colors=2)\n",
    "[axes[1].plot(np.linspace(0, 1, bins+1)[1:], sp_bincount[:,i+len(layer_legend[:-2])], c=fc_colors[i]) for i in range(2)]\n",
    "axes[1].set_xlim((0,0.6))\n",
    "axes[1].legend(layer_legend[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Fig 1B or SS Fig 2B\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=[4,6])\n",
    "# Conv\n",
    "axes[0].plot(layer_legend[:-2], sp_median[:-2], c='tab:blue')\n",
    "axes[0].set_ylim((0,0.4))\n",
    "# FC\n",
    "axes[1].plot(layer_legend[-2:], sp_median[-2:], c='orange')\n",
    "axes[1].set_ylim((0,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats trend test\n",
    "sp_alllayer = np.asarray(sp).reshape(-1)\n",
    "h_index = np.repeat(np.arange(len(sp))+1 , sp[0].shape)\n",
    "tau = stats.kendalltau(h_index, sp_alllayer)\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt SS Fig 1\n",
    "# pdf fit\n",
    "dist_model = ['norm','weibull']\n",
    "log_lik = np.zeros((len(layer_name), len(dist_model)))\n",
    "weib_paras = []\n",
    "for i in range(len(layer_name)):\n",
    "    data = pdf_bin[:, i] \n",
    "    row = 0\n",
    "    # norm\n",
    "    norm_para = stats.norm.fit(data)\n",
    "    log_lik[i, row] = np.sum(stats.norm.logpdf(data, *norm_para)) \n",
    "    row += 1\n",
    "    # weibull\n",
    "    weib_para = stats.weibull_min.fit(data)\n",
    "    log_lik[i, row] = np.sum(stats.weibull_min.logpdf(data, *weib_para)) \n",
    "    weib_paras.append(weib_para)\n",
    "    row += 1\n",
    "weib_k = np.asarray(weib_paras)[:,0]\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=[4,8])\n",
    "# Conv\n",
    "[axes[0].plot(np.arange(0,1,0.01)[1:], pdf_bin[:,i], c=conv_colors[i]) for i in range(len(layer_legend[:-2]))]\n",
    "axes[0].set_xlim((0,0.6))\n",
    "axes[0].legend(layer_legend[:-2])\n",
    "# FC\n",
    "[axes[1].plot(np.arange(0,1,0.01)[1:], pdf_bin[:,i+len(layer_legend[:-2])], c=fc_colors[i]) for i in range(2)]\n",
    "axes[1].set_xlim((0,0.6))\n",
    "axes[1].legend(layer_legend[-2:])\n",
    "# comparison of fitting with Norm and Weibull\n",
    "axes[2].plot(layer_legend, -1* log_lik)\n",
    "axes[2].legend(dist_model)\n",
    "# k in Weibull\n",
    "axes[3].plot(layer_legend, weib_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
